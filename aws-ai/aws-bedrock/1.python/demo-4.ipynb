{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "aef9fbcd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "### Response with High top_p (0.9) - More Creative & Diverse:\n",
      "\n",
      "The future of artificial intelligence (AI) holds immense potential and promises\n",
      "to revolutionize various aspects of our lives. As AI technologies continue to\n",
      "advance, we can expect to see more sophisticated and intelligent systems that\n",
      "can tackle complex tasks with greater efficiency and accuracy. From healthcare\n",
      "to transportation, education to entertainment, AI will play a pivotal role in\n",
      "enhancing our experiences and solving challenging problems. However, it is\n",
      "crucial to address ethical concerns and ensure that AI development is guided by\n",
      "principles of transparency, accountability, and respect for human rights. With\n",
      "responsible development and implementation, AI has the power to unlock new\n",
      "frontiers of innovation and create a better, more sustainable future for\n",
      "humanity.\n",
      "\n",
      "### Response with Low top_p (0.1) - More Predictable & Focused:\n",
      "\n",
      "The future of artificial intelligence (AI) holds immense potential and promises\n",
      "to revolutionize various aspects of our lives. As AI technology continues to\n",
      "advance, we can expect to see more sophisticated and intelligent systems capable\n",
      "of tackling complex tasks with greater efficiency and accuracy. From healthcare\n",
      "and scientific research to transportation and entertainment, AI will play a\n",
      "pivotal role in enhancing our capabilities and improving our quality of life.\n",
      "However, it is crucial to address ethical concerns and ensure that AI\n",
      "development is guided by principles of transparency, accountability, and respect\n",
      "for human rights. With responsible development and implementation, AI has the\n",
      "power to unlock new frontiers of innovation and create a better, more\n",
      "sustainable future for humanity.\n",
      "\n",
      "### Response with Medium top_p (0.5) and Temperature (0.9) - Balanced:\n",
      "\n",
      "The future of artificial intelligence (AI) holds immense potential and promises\n",
      "to revolutionize various aspects of our lives. As AI technology continues to\n",
      "advance, we can expect to see more sophisticated and intelligent systems capable\n",
      "of tackling complex tasks with greater efficiency and accuracy. From healthcare\n",
      "and scientific research to transportation and entertainment, AI will play a\n",
      "pivotal role in enhancing our capabilities and improving our quality of life.\n",
      "However, it is crucial to address ethical concerns and ensure that AI\n",
      "development is guided by principles of transparency, accountability, and respect\n",
      "for human rights. With responsible development and implementation, AI has the\n",
      "power to unlock new frontiers of innovation and create a better, more\n",
      "sustainable future for humanity.\n",
      "\n",
      "### Cosine Similarity between high top_p (0.9) and low top_p (0.1) outputs:\n",
      "Cosine Similarity: 0.9936\n",
      "\n",
      "### Cosine Similarity between high top_p (0.9) and medium top_p (0.5) outputs:\n",
      "Cosine Similarity: 0.9936\n",
      "\n",
      "### Cosine Similarity between low top_p (0.1) and medium top_p (0.5) outputs:\n",
      "Cosine Similarity: 1.0000\n"
     ]
    }
   ],
   "source": [
    "import boto3\n",
    "import json\n",
    "import numpy as np\n",
    "import textwrap\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "\n",
    "# Initialize Bedrock client\n",
    "bedrock_runtime = boto3.client(\"bedrock-runtime\", region_name=\"us-east-1\")\n",
    "\n",
    "# Define the prompt\n",
    "prompt_text = \"Write a short paragraph about the future of artificial intelligence.\"\n",
    "\n",
    "# Function to get text embeddings using Bedrock\n",
    "def get_text_embedding(text):\n",
    "    payload = {\"inputText\": text}\n",
    "\n",
    "    response = bedrock_runtime.invoke_model(\n",
    "        modelId=\"amazon.titan-embed-text-v2:0\",  # Embedding model\n",
    "        contentType=\"application/json\",\n",
    "        accept=\"application/json\",\n",
    "        body=json.dumps(payload),\n",
    "    )\n",
    "\n",
    "    response_body = json.loads(response[\"body\"].read())\n",
    "    embedding = response_body.get(\"embedding\", [])\n",
    "    return np.array(embedding, dtype=float)\n",
    "\n",
    "# Text generation (Claude) â€” now accepts optional temperature param\n",
    "def generate_response(top_p_value: float, temperature: float = 0.7) -> str:\n",
    "    body = {\n",
    "        \"anthropic_version\": \"bedrock-2023-05-31\",\n",
    "        \"messages\": [\n",
    "            {\n",
    "                \"role\": \"user\",\n",
    "                \"content\": [{\"type\": \"text\", \"text\": prompt_text}],\n",
    "            }\n",
    "        ],\n",
    "        \"max_tokens\": 200,\n",
    "        \"temperature\": temperature,\n",
    "        \"top_p\": top_p_value,\n",
    "        \"stop_sequences\": [\"\\n\\nHuman:\"],\n",
    "    }\n",
    "\n",
    "    resp = bedrock_runtime.invoke_model(\n",
    "        modelId=\"anthropic.claude-3-sonnet-20240229-v1:0\",\n",
    "        contentType=\"application/json\",\n",
    "        accept=\"application/json\",\n",
    "        body=json.dumps(body),\n",
    "    )\n",
    "\n",
    "    resp_body = json.loads(resp[\"body\"].read())\n",
    "    # Anthropic Messages API returns a list of content blocks\n",
    "    text_chunks = [\n",
    "        block.get(\"text\", \"\")\n",
    "        for block in resp_body.get(\"content\", [])\n",
    "        if block.get(\"type\") == \"text\"\n",
    "    ]\n",
    "    return textwrap.fill(\"\".join(text_chunks).strip(), width=80)\n",
    "\n",
    "# Generate responses with different top_p / temperature values\n",
    "high_top_p_response = generate_response(0.9, 0.7)   # High top_p and default temperature\n",
    "low_top_p_response = generate_response(0.1, 0.7)    # Low top_p and default temperature\n",
    "medium_top_p_response = generate_response(0.5, 0.9) # Medium top_p with higher temperature\n",
    "\n",
    "# Get embeddings for all three responses\n",
    "high_top_p_embedding = get_text_embedding(high_top_p_response)\n",
    "low_top_p_embedding = get_text_embedding(low_top_p_response)\n",
    "medium_top_p_embedding = get_text_embedding(medium_top_p_response)\n",
    "\n",
    "# Compute cosine similarity between the three embeddings (sklearn)\n",
    "similarity_high_low = cosine_similarity([high_top_p_embedding], [low_top_p_embedding])\n",
    "similarity_high_medium = cosine_similarity([high_top_p_embedding], [medium_top_p_embedding])\n",
    "similarity_low_medium = cosine_similarity([low_top_p_embedding], [medium_top_p_embedding])\n",
    "\n",
    "# Print the responses and similarity scores\n",
    "print(\"\\n### Response with High top_p (0.9) - More Creative & Diverse:\\n\")\n",
    "print(high_top_p_response)\n",
    "\n",
    "print(\"\\n### Response with Low top_p (0.1) - More Predictable & Focused:\\n\")\n",
    "print(low_top_p_response)\n",
    "\n",
    "print(\"\\n### Response with Medium top_p (0.5) and Temperature (0.9) - Balanced:\\n\")\n",
    "print(medium_top_p_response)\n",
    "\n",
    "print(\"\\n### Cosine Similarity between high top_p (0.9) and low top_p (0.1) outputs:\")\n",
    "print(f\"Cosine Similarity: {similarity_high_low[0][0]:.4f}\")\n",
    "\n",
    "print(\"\\n### Cosine Similarity between high top_p (0.9) and medium top_p (0.5) outputs:\")\n",
    "print(f\"Cosine Similarity: {similarity_high_medium[0][0]:.4f}\")\n",
    "\n",
    "print(\"\\n### Cosine Similarity between low top_p (0.1) and medium top_p (0.5) outputs:\")\n",
    "print(f\"Cosine Similarity: {similarity_low_medium[0][0]:.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66f458e3",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
